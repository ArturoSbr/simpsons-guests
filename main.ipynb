{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Simpsons episodes\n",
    "This notebook scrapes all the episodes from The Simpsons.\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape all episode tables\n",
    "\n",
    "Get the text from all `wikitable plainrowheaders wikiepisodetable` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get request\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_The_Simpsons_episodes_(seasons_1%E2%80%9320)'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# Find all episode tables\n",
    "tables = soup.find_all(\n",
    "    name='table',\n",
    "    attrs={\n",
    "        'class': 'wikitable plainrowheaders wikiepisodetable'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile all the tables into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to retrieve\n",
    "cols = [\n",
    "    'Title',\n",
    "    'Original air date',\n",
    "    'U.S. viewers (millions)'\n",
    "]\n",
    "\n",
    "# Read all tables and concat them together\n",
    "for i, j in enumerate(tables):\n",
    "        \n",
    "    # Read HTML (omit movies)\n",
    "    try:\n",
    "        d = pd.read_html(str(j))[0][cols]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Init dataframe\n",
    "    if i == 0:\n",
    "\n",
    "        # Declare `df`\n",
    "        df = d\n",
    "    \n",
    "    # Append subsequent frames\n",
    "    else:\n",
    "\n",
    "        # Concat to `df`\n",
    "        df = pd.concat([df, d])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean episodes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.columns = [\n",
    "    'title',\n",
    "    'release',\n",
    "    'viewers'\n",
    "]\n",
    "\n",
    "# Clean title column\n",
    "df['title'] = df['title'].str.replace('\"', '')\n",
    "\n",
    "# Turn date to datetime\n",
    "df['release'] = pd.to_datetime(\n",
    "    arg=df['release'],\n",
    "    format='%B %d, %Y'\n",
    ")\n",
    "\n",
    "# Clean viewers\n",
    "df['viewers'] = df['viewers'].str.split('[').str[0].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Special Guests list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get request\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_The_Simpsons_guest_stars_(seasons_1%E2%80%9320)'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "# Find all guests table\n",
    "guests = soup.find(\n",
    "    name='table',\n",
    "    attrs={\n",
    "        'class': 'wikitable'\n",
    "    }\n",
    ")\n",
    "\n",
    "# To pandas\n",
    "gs = pd.read_html(str(guests))[0][['Season', 'Episode title']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean guests table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "gs.columns = ['season', 'title']\n",
    "\n",
    "# Remove \" from title column\n",
    "gs['title'] = gs['title'].str.replace('\"', '')\n",
    "\n",
    "# Split title column on \"[\"\n",
    "gs['title'] = gs['title'].str.split('[').str[0]\n",
    "\n",
    "# Groupby\n",
    "gs.groupby('title').size().reset_index(\n",
    "    name='n_guests'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
